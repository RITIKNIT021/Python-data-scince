# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1asIimKlP-pDey_cY-dr7zwykUKSccTfk
"""

from sklearn.datasets import make_classification

x,y=make_classification(n_samples=1000,n_features=2,n_redundant=0,n_clusters_per_class=1,weights=[0.90],random_state=1)

import pandas as pd
df1=pd.DataFrame(x,columns=["f1","f2"])
df2=pd.DataFrame(y,columns=["target"])
f_df=pd.concat([df1,df2],axis=1)

f_df.head()

f_df['target'].value_counts()

import matplotlib.pyplot as plt
plt.scatter(f_df['f1'],f_df['f2'],c=f_df['target'])

!pip install imblearn

from imblearn.over_sampling import SMOTE
oversample=SMOTE()
x,y=oversample.fit_resample(f_df[['f1','f2']],f_df['target'])

x.shape

df1=pd.DataFrame(x,columns=["f1","f2"])
df2=pd.DataFrame(y,columns=["target"])
o_df=pd.concat([df1,df2],axis=1)
plt.scatter(o_df['f1'],o_df['f2'],c=o_df['target'])

"""Linear interpolution"""

import numpy as np
a=np.array([1,2,3,4,5])
b=np.array([6,7,8,9,10])

import matplotlib.pyplot as plt
plt.scatter(a,b)

x_new=np.linspace(1,5,10) #crate new values of a
y_interp=np.interp(x_new,a,b)#interplote y values
plt.scatter(x_new,y_interp)

"""Cubic inter polation"""

from scipy.interpolate import interp1d
a=np.array([1,2,3,4,5])
b=np.array([1,8,27,64,125])

plt.scatter(a,b)

f=interp1d(a,b,kind="cubic")

x_new=np.linspace(1,5,10)
y_interp=f(x_new)

plt.scatter(x_new,y_interp)

"""Ploynomial interplotion

"""

p=np.polyfit(a,b,5)

x_new=np.linspace(1,5,10)
y_interp=np.polyval(p,x_new)

plt.scatter(x_new,y_interp)

import numpy as np

l1=[-88,-55,8,6,4,8,2,11,44,5,55,6,444,45555]

q1=np.percentile(l1,[25])
q1

min,q1,q2,q3,max=np.quantile(l1,[0,0.25,0.50,0.75,1])

q3

iqr=q3-q1

lower_fence=q1-1.5*(iqr)
higher_fence=q3+1.5*(iqr)

lower_fence,higher_fence

outliers=[]
for i in l1:
  if i<-43.0 and i>83.0:
    print("This is outliers")
  else:
    outliers.append(i)

print(outliers)

import seaborn as sns
sns.boxplot(l1)

import seaborn as sns
df=sns.load_dataset('taxis')
df.head()

from sklearn.preprocessing import MinMaxScaler

min_max=MinMaxScaler()
min_max

min_max.fit(df[['distance','fare','tip']])

min_max.transform(df[['distance','fare','tip']]) #you can use the fit_transform()

min_max.transform([[2,3,5]])

import seaborn as sns
df=sns.load_dataset('iris')
df.head()

from sklearn.preprocessing import normalize

df.columns

x=normalize(df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']])

import pandas as pd
df=pd.DataFrame(x,columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])
df

"""One hot encoding"""

import pandas as pd
from sklearn.preprocessing import OneHotEncoder

df=pd.DataFrame({'colors':['red','green','blue','blue']})
df

encoder=OneHotEncoder()

encoded=encoder.fit_transform(df[['colors']]).toarray()

df1=pd.DataFrame(encoded,columns=encoder.get_feature_names_out())
df1

pd.concat([df1,df],axis=1)

"""Label encoding"""

from sklearn.preprocessing import LabelEncoder

df=pd.DataFrame({'colors':['red','green','blue','blue']})
df

encoder=LabelEncoder()

encoded=encoder.fit_transform(df['colors'])
encoded

from sklearn.preprocessing import OrdinalEncoder
df=pd.DataFrame({'colors':['red','green','blue','blue']})
df

encoder=OrdinalEncoder(categories=[['red','green','blue','blue']])
encoder

encoder.fit_transform(df[['colors']])

"""Target guided ordinal encoding"""

df=pd.DataFrame({'city':['New_york','USA','Landon','New_york'],
                 'prize':[100,150,300,200]})
df

mean_prize=df.groupby('city')['prize'].mean().to_dict()
mean_prize

df['encoded']=df['city'].map(mean_prize)
df